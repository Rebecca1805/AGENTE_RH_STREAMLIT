# -*- coding: utf-8 -*-
"""agente.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r76sva4Z8EeVoSUuHl3TkmUwvkfzA1bS
"""

from pathlib import Path
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import RetrievalQA


def carregar_documentos(folder_path="DADOS"):
    """Carrega todos os PDFs da pasta fornecida e retorna lista de documentos."""
    docs = []
    for n in Path(folder_path).glob("*.pdf"):
        try:
            loader = PyMuPDFLoader(str(n))
            docs.extend(loader.load())
            print(f"Carregado com sucesso arquivo {n.name}")
        except Exception as e:
            print(f"Erro ao carregar arquivo {n.name}: {e}")
    print(f"Total de documentos carregados: {len(docs)}")
    return docs


def carregar_agente(folder_path="DADOS"):
    """Inicializa o agente baseado nos documentos PDF da pasta especificada."""
    docs = carregar_documentos(folder_path)
    if not docs:
        raise ValueError("Nenhum documento PDF encontrado na pasta data/")

    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    splits = splitter.split_documents(docs)

    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    vectorstore = FAISS.from_documents(splits, embeddings)
    retriever = vectorstore.as_retriever()

    llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.0,
    api_key=GOOGLE_API_KEY
)

    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "VocÃª Ã© um Assistente de PolÃ­ticas Internas (RH/IT) da empresa Carraro Desenvolvimento. "
         "Responda SOMENTE com base no contexto fornecido. "
         "Se nÃ£o houver base suficiente, responda apenas 'NÃ£o sei'."),
        ("human", "{input}")
    ])

    chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt}
    )
    return chain


def responder_agente(agente, pergunta: str) -> str:
    """Recebe uma pergunta e retorna a resposta do agente."""
    resposta = agente.invoke({"query": pergunta})
    if isinstance(resposta, dict) and "result" in resposta:
        return resposta["result"]
    return str(resposta)

# --- Interface Streamlit ---
st.set_page_config(page_title="BECC Agent", page_icon="ğŸ¤–")
st.title("ğŸ¤– BECC Agent")
st.write("Digite sua pergunta abaixo:")

if "agente" not in st.session_state:
    st.session_state["agente"] = carregar_agente("data")

pergunta = st.text_input("Sua pergunta:")

if st.button("Enviar"):
    resposta = responder_agente(st.session_state["agente"], pergunta)
    st.success(resposta)
